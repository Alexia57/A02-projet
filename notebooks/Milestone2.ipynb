{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'.env')\n",
    "import os\n",
    "temp = os.environ.get('COMET_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/ift6758-a02/milestone2/9698eb944b8f4c95ae2ee66f31abf8db\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     acc  : 0.8\n",
      "COMET INFO:     auc  : 12\n",
      "COMET INFO:     loss : 0.65\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/ift6758-a02/milestone2/ebbb9e7451964a4c82a09a377732ccd8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Unknown error exporting current conda environment\n",
      "COMET WARNING: Unknown error retrieving Conda package as an explicit file\n",
      "COMET WARNING: Unknown error retrieving Conda information\n"
     ]
    }
   ],
   "source": [
    "# Importer comet_ml en haut de votre fichier, avant sklearn !\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Créer une expérience avec votre clé api\n",
    "exp = Experiment(\n",
    "    api_key=os.environ.get(temp),#ne pas coder en dur!\n",
    "    project_name='milestone2',\n",
    "    workspace='ift6758-a02',\n",
    ")\n",
    "# ... Faire de la science des données ...\n",
    "exp.log_metrics({\"auc\": 12, \"acc\": 0.8, \"loss\": 0.65})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingénierie des caractéristiques I (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données\n",
    "\n",
    "def clean_data(path) :\n",
    "    \"\"\"\n",
    "    Nettoie un DataFrame de données de jeu NHL à partir d'un fichier JSON.\n",
    "\n",
    "    Args:\n",
    "        path (str): Le chemin vers le fichier JSON contenant les données de jeu NHL.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame propre contenant les colonnes 'emptyNet', 'isGoal',\n",
    "                     'x', 'y', 'distanceToNet', et 'relativeAngleToNet'.\n",
    "\n",
    "    \"\"\"\n",
    "    # Charger les données JSON en un DataFrame\n",
    "    df = pd.read_json(path)\n",
    "\n",
    "    # Extraire les informations des équipes, des événements de jeu et des résultats de jeu\n",
    "    teamdf = df['gameData'].apply(pd.Series)['teams'].apply(pd.Series)\n",
    "    df = df['liveData'].apply(pd.Series)['plays'].apply(pd.Series)['allPlays']\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.explode(\"allPlays\")\n",
    "    df = df.rename(columns={'allPlays': \"play\"})\n",
    "\n",
    "    # Ajouter les noms des équipes 'awayTeam' et 'homeTeam'\n",
    "    df['awayTeam'] = teamdf['away'].apply(pd.Series)['name']\n",
    "    df['homeTeam'] = teamdf['home'].apply(pd.Series)['name']\n",
    "\n",
    "    # Extraire les données d'événements 'play' pour obtenir les informations pertinentes\n",
    "    df = df['play'].apply(pd.Series)\n",
    "    df = pd.concat([df, df['result'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Filtrer les événements pour inclure uniquement 'Shot' et 'Goal'\n",
    "    df = df[df['event'].isin(['Shot', 'Goal'])]\n",
    "\n",
    "    # Extraire les coordonnées x et y des événements\n",
    "    df['x'] = df['coordinates'].apply(pd.Series)['x']\n",
    "    df['y'] = df['coordinates'].apply(pd.Series)['y']\n",
    "\n",
    "    # Créer un nouveau DataFrame avec les colonnes pertinentes\n",
    "    clean_df = df[['event',  'emptyNet','x','y']].copy()\n",
    "\n",
    "    # Remplir les valeurs manquantes dans 'emptyNet' avec 0 et convertir en entier\n",
    "    clean_df['emptyNet'] = clean_df['emptyNet'].fillna(0).astype(int)\n",
    "\n",
    "    # Créer une nouvelle colonne 'isGoal' pour indiquer si l'événement est un but (1) ou non (0)\n",
    "    clean_df['isGoal'] = (clean_df['event'] == 'Goal').astype(int)\n",
    "    clean_df.drop('event',axis=1, inplace=True)\n",
    "\n",
    "    # Coordonnées des camps gauche et droit\n",
    "    coord_camp_gauche = (-90, 0)\n",
    "    coord_camp_droit = (90, 0)\n",
    "\n",
    "    # Calculer la distance du joueur au filet en utilisant les coordonnées x et y\n",
    "    clean_df['distanceToNet'] = np.sqrt(np.minimum((clean_df['x'] - coord_camp_gauche[0])**2 + (clean_df['y'] - coord_camp_gauche[1])**2, (clean_df['x'] - coord_camp_droit[0])**2 + (clean_df['y'] - coord_camp_droit[1])**2))\n",
    "    \n",
    "    # Calculer l'angle relatif du joueur par rapport au filet (filet gauche)\n",
    "    clean_df['relativeAngleToNet'] = np.degrees(np.arctan2(clean_df['y'], clean_df['x'] - coord_camp_gauche[0]))\n",
    "\n",
    "    # Ajouter la colonne 'season' en extrayant l'année du chemin du fichier JSON\n",
    "    clean_df['season'] = int(path[-9:-5])\n",
    "\n",
    "    # Sauvegarder le DataFrame propre dans un fichier CSV\n",
    "    clean_df.to_csv(path[:-5]+\"_clean_M2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# division des données en Ensemble de test et d'entrainement / validation\n",
    "\n",
    "def split_data(path) :\n",
    "    df = pd.read_csv(path)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.drop(columns=['Unnamed: 0.1'])\n",
    "    \n",
    "    train_data = df.loc[df['season'] != 2020]\n",
    "    test_data = df.loc[df['season'] == 2020]\n",
    "\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_data.to_csv(\"nhl_train_data.csv\")\n",
    "    test_data.to_csv(\"nhl_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution du code  (c'est long )\n",
    "clean_data('nhl_data_2016.json') # ==> nouveau fichier nhl_data_2016_clean_M2.csv\n",
    "clean_data('nhl_data_2017.json') # ==> nouveau fichier nhl_data_2017_clean_M2.csv\n",
    "clean_data('nhl_data_2018.json') # ==> nouveau fichier nhl_data_2018_clean_M2.csv\n",
    "clean_data('nhl_data_2019.json') # ==> nouveau fichier nhl_data_2019_clean_M2.csv\n",
    "clean_data('nhl_data_2020.json') # ==> nouveau fichier nhl_data_2020_clean_M2.csv\n",
    "\n",
    "p_clean = [\"nhl_data_2016_clean_M2.csv\",\"nhl_data_2017_clean_M2.csv\", \"nhl_data_2018_clean_M2.csv\", \"nhl_data_2019_clean_M2.csv\", \"nhl_data_2020_clean_M2.csv\"]\n",
    "df_list = []\n",
    "count = 0\n",
    "for path in p_clean:\n",
    "    df = pd.read_csv(path)\n",
    "    df['Unnamed: 0'] = df['Unnamed: 0']+count\n",
    "    count = df['Unnamed: 0'].values[-1]\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "df.to_csv('nhl_all_years_clean_M2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data('nhl_all_years_clean_M2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('ift6758')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76f24fe593248544fb53c45860141e2f5868563163d477b8bfa09ccbbd1149dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
